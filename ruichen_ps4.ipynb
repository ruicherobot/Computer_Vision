{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix5dQS2rUMlu"
      },
      "source": [
        "#EECS 442/504 PS4: Backpropagation\n",
        "\n",
        "__Please provide the following information__\n",
        "(e.g. Andrew Owens, ahowens):\n",
        "\n",
        "[Your first name] [Your last name], [Your UMich uniqname]\n",
        "\n",
        "__Important__: after you download the .ipynb file, please name it as __\"PS\\<this_ps_number\\>_\\<your_uniqname\\>.ipynb\"__ before you submit it to canvas. Example: adam_01101100.ipynb.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Cst4k4tuBc"
      },
      "source": [
        "# Starting\n",
        "\n",
        "Run the following code to import the modules you'll need. After your finish the assignment, remember to run all cells and save the note book to your local machine as a .ipynb file for Canvas submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHumIO-xt57H"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "from torchvision.datasets import CIFAR10\n",
        "download = not os.path.isdir('cifar-10-batches-py')\n",
        "dset_train = CIFAR10(root='.', download=download)\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87aUvJJ52FeY"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WpKb7SvKR6W"
      },
      "source": [
        "# Problem 4.1 Understanding Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy-7c_kJKUCd"
      },
      "source": [
        "# 4.1 (b)  \n",
        "Implement the code for forward and backward pass of computation graph in (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yojDcdIzXcNB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import T\n",
        "def f_1(x0, x1, x2, w0, w1, w2, w3):\n",
        "    \"\"\"\n",
        "    Computes the forward and backward pass through the computational graph \n",
        "    of (a)\n",
        "\n",
        "    Inputs:\n",
        "    - x0, x1, x2, w0, w1, w2, w3: Python floats\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - L: The output of the graph\n",
        "    - grads: A tuple (grad_x0, grad_x1, grad_x2, grad_w0, grad_w1, grad_w2, \n",
        "      grad_w3)\n",
        "    giving the derivative of the output L with respect to each input.\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the forward pass for the computational graph for (a) and#\n",
        "    # store the output of this graph as L                                     #\n",
        "    ###########################################################################\n",
        "\n",
        "    q0 = w0 + x0\n",
        "    q1 = w1 + x1\n",
        "    p2 = w2 * (-1)\n",
        "    p3 = x2 ** (-1)\n",
        "    r = q0 + q1\n",
        "    s = p2 * p3\n",
        "    t = s + w3\n",
        "    u = r + T\n",
        "    v = u * (-1)\n",
        "    h = np.exp(v)\n",
        "    g = h + 1\n",
        "    f = g ** (-1)\n",
        "    L = f\n",
        "    \n",
        "    ###########################################################################\n",
        "    #                              END OF YOUR CODE                           #\n",
        "    ###########################################################################\n",
        "    \n",
        "    ###########################################################################\n",
        "    # TODO: Implement the backward pass for the computational graph for (a)   #\n",
        "    # Store the gradients for each input                                      #\n",
        "    ###########################################################################\n",
        "\n",
        "    grad_L = 1\n",
        "    grad_f = grad_L * 1\n",
        "    grad_g = grad_f * (-1.0) / g ** (2)\n",
        "    grad_h = grad_g * 1\n",
        "    grad_v = grad_h * np.exp(v)\n",
        "    grad_u = grad_v * (-1)\n",
        "    grad_r = grad_u * 1\n",
        "    grad_t = grad_u * 1\n",
        "    grad_s = grad_t * 1\n",
        "    grad_w3 = grad_t * 1\n",
        "    grad_p2 = grad_s * p3\n",
        "    grad_p3 = grad_s * p2\n",
        "    grad_q0 = grad_r * 1\n",
        "    grad_q1 = grad_r * 1\n",
        "    grad_x0 = grad_q0 * w0\n",
        "    grad_w0 = grad_q0 * x0\n",
        "    grad_x1 = grad_q1 * w1\n",
        "    grad_w1 = grad_q1 * x1\n",
        "    grad_x2 = grad_p3 * (-1.0) / x2 ** (2)\n",
        "    grad_w2 = grad_p2 *(-1)\n",
        "    ###########################################################################\n",
        "    #                              END OF YOUR CODE                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    grads = (grad_x0, grad_x1, grad_x2, grad_w0, grad_w1, grad_w2, grad_w3)\n",
        "    return L, grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdquTNqGKYcc"
      },
      "source": [
        "# 4.1 (c)  \n",
        "Implement the code for forward and backward pass of computation graph in (c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o55wTks0KaPC"
      },
      "outputs": [],
      "source": [
        "def f_2(w, x, y, z):\n",
        "    \"\"\"\n",
        "    Computes the forward and backward pass through the computational graph \n",
        "    of (c)\n",
        "\n",
        "    Inputs:\n",
        "    - w, x, y, z: Python floats\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - L: The output of the graph\n",
        "    - grads: A tuple (grad_w, grad_x, grad_y, grad_z)\n",
        "    giving the derivative of the output L with respect to each input.\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the forward pass for the computational graph for (c) and#\n",
        "    # store the output of this graph as L                                     #\n",
        "    ###########################################################################\n",
        "    a = w ** (-1)\n",
        "    b = x ** (-1)\n",
        "    e = a ** (b)\n",
        "\n",
        "    c = np.exp(y)\n",
        "    d = np.exp(z)\n",
        "    p = c * d\n",
        "    g = d / p\n",
        "    f = c + p\n",
        "    m = e - f\n",
        "    n = m / g\n",
        "    L = n ** 2\n",
        "    ###########################################################################\n",
        "    #                              END OF YOUR CODE                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the backward pass for the computational graph for (c)   #\n",
        "    # Store the gradients for each input                                      #\n",
        "    ###########################################################################\n",
        "    grad_L = 1\n",
        "    grad_n = grad_L * 2 * n\n",
        "    grad_g = grad_n * (-1.0) * m / g ** 2\n",
        "    grad_m = grad_n / g\n",
        "    grad_f = grad_m * (-1.0)\n",
        "    grad_e = grad_m * 1.0\n",
        "    grad_p = grad_f * 1.0 + grad_g * (-1.0) * d / p ** 2\n",
        "    grad_c = grad_f * 1.0 + grad_p * d\n",
        "    grad_d = grad_g / p + grad_p * c\n",
        "    grad_a = grad_e * b * a ** (b - 1)\n",
        "    grad_b = grad_e * a ** (b) * np.log(a)\n",
        "    grad_w = grad_a * (-1.0) / w ** 2\n",
        "    grad_x = grad_b * (-1.0) / x ** 2\n",
        "    grad_y = grad_c * c\n",
        "    grad_z = grad_d * d\n",
        "    ###########################################################################\n",
        "    #                              END OF YOUR CODE                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    grads = (grad_w, grad_x, grad_y, grad_z)\n",
        "    return L, grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apEPzDNtK0MC"
      },
      "source": [
        "# Problem 4.2 Softmax Classifier with Two Layer Neural Network\n",
        "In this problem you will develop a two Layer neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset.\n",
        "\n",
        "We train the network with a softmax loss function on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture:\n",
        "\n",
        "input - fully connected layer - ReLU - fully connected layer - softmax\n",
        "\n",
        "The outputs of the second fully-connected layer are the scores for each class.\n",
        "\n",
        "You cannot use any deep learning libraries such as PyTorch in this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXfumCQ21JoK"
      },
      "source": [
        "# 4.2 (a) Layers\n",
        "In this problem, implement fully connected layer, relu and softmax. Filling in all TODOs in skeleton codes will be sufficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-ljfgMv9PHx"
      },
      "outputs": [],
      "source": [
        "def fc_forward(X, W, b):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a fully-connected layer.\n",
        "    \n",
        "    The input X has shape (N, Din) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (Din,).\n",
        "    \n",
        "    Inputs:\n",
        "    - X: A numpy array containing input data, of shape (N, Din)\n",
        "    - W: A numpy array of weights, of shape (Din, Dout)\n",
        "    - b: A numpy array of biases, of shape (Dout,)\n",
        "    \n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, Dout)\n",
        "    - cache: (X, W, b)\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the forward pass. Store the result in out.              #\n",
        "    ###########################################################################\n",
        "    # print(\"~~~~~~~~~~~~~~~~\")\n",
        "    # print(X.shape)\n",
        "    # print(W.shape)\n",
        "    # print(b.shape)\n",
        "    # print(\"~~~~~~~~~~~~~~~~\")\n",
        "    out = np.dot(X, W) + np.transpose(b)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = (X, W, b)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def fc_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a fully_connected layer.\n",
        "    \n",
        "    Inputs:\n",
        "    - dout: Upstream derivative, of shape (N, Dout)\n",
        "    - cache: returned by your forward function. Tuple of:\n",
        "      - X: Input data, of shape (N, Din)\n",
        "      - W: Weights, of shape (Din, Dout)\n",
        "      - b: Biases, of shape (Dout,)\n",
        "      \n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient with respect to X, of shape (N, Din)\n",
        "    - dW: Gradient with respect to W, of shape (Din, Dout)\n",
        "    - db: Gradient with respect to b, of shape (Dout,)\n",
        "    \"\"\"\n",
        "    X, W, b = cache\n",
        "    dX, dW, db = None, None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the affine backward pass.                               #\n",
        "    ###########################################################################\n",
        "    # print(\"++++++++++++++++\")\n",
        "    # print(X.shape)\n",
        "    # print(W.shape)\n",
        "    # print(b.shape)\n",
        "    # print(\"---------------\")\n",
        "    dX = np.dot(dout, np.transpose(W))\n",
        "    dW = np.dot(np.transpose(X), dout)\n",
        "    db = np.dot(np.transpose(dout), np.ones((dout.shape[0], 1)))\n",
        "    # print(dX.shape)\n",
        "    # print(dW.shape)\n",
        "    # print(db.shape)\n",
        "    # print(\"++++++++++++++++\")\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dX, dW, db\n",
        "\n",
        "def relu_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - x: Inputs, of any shape\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output, of the same shape as x\n",
        "    - cache: x\n",
        "    \"\"\"\n",
        "    out = x.copy()\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU forward pass.                                  #\n",
        "    ###########################################################################\n",
        "    \n",
        "    for i in range(out.shape[0]):\n",
        "      for j in range(out.shape[1]):\n",
        "        if out[i, j] < 0:\n",
        "          out[i, j] = 0\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = x\n",
        "\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def relu_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - dout: Upstream derivatives, of any shape\n",
        "    - cache: returned by your forward function. Input x, of same shape as dout\n",
        "\n",
        "    Returns:\n",
        "    - dx: Gradient with respect to x\n",
        "    \"\"\"\n",
        "    dx, x = dout.copy(), cache\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU backward pass.                                 #\n",
        "    ###########################################################################\n",
        "    for i in range(dout.shape[0]):\n",
        "      for j in range(dout.shape[1]):\n",
        "        if x[i, j] <= 0:\n",
        "          dx[i, j] = 0\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dx\n",
        "\n",
        "\n",
        "def softmax_loss(X, y):\n",
        "    \"\"\"\n",
        "    Computes the loss and gradient for softmax classification.\n",
        "\n",
        "    Inputs:\n",
        "    - X: Input data, of shape (N, C) where x[i, j] is the score for the jth\n",
        "      class for the ith input.\n",
        "    - y: Vector of labels, of shape (N,) where y[i] is the label for X[i] and\n",
        "      0 <= y[i] < C\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - loss: Scalar giving the loss\n",
        "    - dX: Gradient of the loss with respect to x\n",
        "    \"\"\"\n",
        "    loss, dX = None, None\n",
        "\n",
        "    dX = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    dX /= np.sum(dX, axis=1, keepdims=True)\n",
        "    loss = -np.sum(np.log(dX[np.arange(X.shape[0]), y])) / X.shape[0]\n",
        "    dX[np.arange(X.shape[0]), y] -= 1\n",
        "    dX /= X.shape[0]\n",
        "\n",
        "\n",
        "    return loss, dX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFxtS3zK8oz"
      },
      "source": [
        "# 4.2 (b) Two Layer Softmax Classifier\n",
        "\n",
        "In this problem, implement two layer softmax classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytvxbx9UpxVL"
      },
      "outputs": [],
      "source": [
        "class SoftmaxClassifier(object):\n",
        "    \"\"\"\n",
        "    A fully-connected neural network with\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecture should be fc - relu - fc - softmax with one hidden layer\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=3072, hidden_dim=300, num_classes=10,\n",
        "                 weight_scale=1e-3, reg=0.0):\n",
        "        \"\"\"\n",
        "        Initialize a new network.\n",
        "\n",
        "        Inputs:f\n",
        "        - input_dim: An integer giving the size of the input\n",
        "        - hidden_dim: An integer giving the size of the hidden layer, None\n",
        "          if there's no hidden layer.\n",
        "        - num_classes: An integer giving the number of classes to classify\n",
        "        - weight_scale: Scalar giving the standard deviation for random\n",
        "          initialization of the weights.\n",
        "        \"\"\"\n",
        "        self.params = {}\n",
        "        self.reg = reg\n",
        "        ############################################################################\n",
        "        # TODO: Initialize the weights and biases of the two-layer net. Weights    #\n",
        "        # should be initialized from a Gaussian centered at 0.0 with               #\n",
        "        # standard deviation equal to weight_scale, and biases should be           #\n",
        "        # initialized to zero. All weights and biases should be stored in the      #\n",
        "        # dictionary self.params, with fc weights and biases using the keys        #\n",
        "        # 'W' and 'b', i.e., W1, b1 for the weights and bias in the first linear   #\n",
        "        # layer, W2, b2 for the weights and bias in the second linear layer.       #\n",
        "        ############################################################################\n",
        "        self.params['W1'] = np.random.normal(0, weight_scale, (input_dim, hidden_dim))\n",
        "        self.params['b1'] = np.zeros((hidden_dim, 1))\n",
        "        self.params['W2'] = np.random.normal(0, weight_scale, (hidden_dim, num_classes))\n",
        "        self.params['b2'] = np.zeros((num_classes, 1))        \n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "\n",
        "    def forwards_backwards(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute loss and gradient for a minibatch of data.\n",
        "\n",
        "        Inputs:\n",
        "        - X: Array of input data of shape (N, Din)\n",
        "        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].\n",
        "\n",
        "        Returns:\n",
        "        If y is None, then run a test-time forward pass of the model and return:\n",
        "        - scores: Array of shape (N, C) giving classification scores, where\n",
        "          scores[i, c] is the classification score for X[i] and class c.\n",
        "\n",
        "        If y is not None, then run a training-time forward and backward pass. And\n",
        "        return a tuple of:\n",
        "        - loss: Scalar value giving the loss\n",
        "        - grads: Dictionary with the same keys as self.params, mapping parameter\n",
        "          names to gradients of the loss with respect to those parameters.\n",
        "        \"\"\"\n",
        "        scores = None\n",
        "        ############################################################################\n",
        "        # TODO: Implement the forward pass for the two-layer net, computing the    #\n",
        "        # class scores for X and storing them in the scores variable.              #\n",
        "        ############################################################################\n",
        "        out_fc1, cache_fc1 = fc_forward(X, self.params['W1'], self.params['b1'])\n",
        "        out_relu, cache_relu = relu_forward(out_fc1)\n",
        "        out_fc2, cache_fc2 = fc_forward(out_relu, self.params['W2'], self.params['b2'])\n",
        "        scores = out_fc2\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        # If y is None then we are in test mode so just return scores\n",
        "        if y is None:\n",
        "            return scores\n",
        "        loss, grads = 0, {}\n",
        "        ############################################################################\n",
        "        # TODO: Implement the backward pass for the two-layer net. Store the loss  #\n",
        "        # in the loss variable and gradients in the grads dictionary. Compute data #\n",
        "        # loss using softmax, and make sure that grads[k] holds the gradients for  #\n",
        "        # self.params[k].                                                          # \n",
        "        ############################################################################\n",
        "        loss, grad_soft= softmax_loss(scores, y)\n",
        "        # print(out_fc1.shape)\n",
        "        # print(out_relu.shape)\n",
        "        # print(out_fc2.shape)\n",
        "        # print(scores.shape)\n",
        "        # print(\"SLEEPING!\")\n",
        "        grad_fc2, dW_fc2, db_fc2 = fc_backward(grad_soft, cache_fc2)\n",
        "        grads['W2'] = dW_fc2\n",
        "        grads['b2'] = db_fc2\n",
        "        grad_relu = relu_backward(grad_fc2, cache_relu)\n",
        "        grad_fc1, dW_fc1, db_fc1 = fc_backward(grad_relu, cache_fc1)\n",
        "        grads['W1'] = dW_fc1\n",
        "        grads['b1'] = db_fc1\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "        ############################################################################\n",
        "        # TODO: 4.2(g)(EECS 504 only) Add L2 regularization                        # \n",
        "        ############################################################################\n",
        "        loss = loss + self.reg * (np.sum(grads['W1'] ** 2) + np.sum(grads['W2'] ** 2))\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "        return loss, grads\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwp0waIL1h_e"
      },
      "source": [
        "# 4.2(c) Training\n",
        "\n",
        "In this problem, you need to preprocess the images and set up model hyperparameters. Notice that adjust the training and val split is optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZPtQzXGMoCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "ae5c04ec-2ec8-456d-caf9-31477fd942d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 4000) loss: 2.300115\n",
            "(Epoch 0 / 10) train acc: 0.134000; val_acc: 0.119700\n",
            "(Epoch 1 / 10) train acc: 0.328000; val_acc: 0.317900\n",
            "(Epoch 2 / 10) train acc: 0.362000; val_acc: 0.358900\n",
            "(Iteration 1001 / 4000) loss: 1.731960\n",
            "(Epoch 3 / 10) train acc: 0.398000; val_acc: 0.379200\n",
            "(Epoch 4 / 10) train acc: 0.378000; val_acc: 0.397600\n",
            "(Epoch 5 / 10) train acc: 0.407000; val_acc: 0.409400\n",
            "(Iteration 2001 / 4000) loss: 1.598353\n",
            "(Epoch 6 / 10) train acc: 0.429000; val_acc: 0.421900\n",
            "(Epoch 7 / 10) train acc: 0.416000; val_acc: 0.431300\n",
            "(Iteration 3001 / 4000) loss: 1.501859\n",
            "(Epoch 8 / 10) train acc: 0.467000; val_acc: 0.437500\n",
            "(Epoch 9 / 10) train acc: 0.494000; val_acc: 0.444100\n",
            "(Epoch 10 / 10) train acc: 0.496000; val_acc: 0.452200\n",
            "~~~~~~~~~~ 299.64987540245056 seconds ~~~~~~~~~~\n"
          ]
        }
      ],
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding=\"latin1\")\n",
        "    return dict\n",
        "\n",
        "def load_cifar10():\n",
        "    data = {}\n",
        "    meta = unpickle(\"cifar-10-batches-py/batches.meta\")\n",
        "    batch1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
        "    batch2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
        "    batch3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
        "    batch4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
        "    batch5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
        "    test_batch = unpickle(\"cifar-10-batches-py/test_batch\")\n",
        "    X_train = np.vstack((batch1['data'], batch2['data'], batch3['data'],\\\n",
        "                         batch4['data'], batch5['data']))\n",
        "    Y_train = np.array(batch1['labels'] + batch2['labels'] + batch3['labels'] + \n",
        "                       batch4['labels'] + batch5['labels'])\n",
        "    X_test = test_batch['data']\n",
        "    Y_test = test_batch['labels']\n",
        "    \n",
        "    #Preprocess images here                                     \n",
        "    X_train = (X_train-np.mean(X_train,axis=1,keepdims=True))/np.std(X_train,axis=1,keepdims=True)\n",
        "    X_test = (X_test-np.mean(X_test,axis=1,keepdims=True))/np.std(X_test,axis=1,keepdims=True)\n",
        "\n",
        "    data['X_train'] = X_train[:40000]\n",
        "    data['y_train'] = Y_train[:40000]\n",
        "    data['X_val'] = X_train[40000:]\n",
        "    data['y_val'] = Y_train[40000:]\n",
        "    data['X_test'] = X_test\n",
        "    data['y_test'] = Y_test\n",
        "    return data\n",
        "\n",
        "def testNetwork(model, X, y, num_samples=None, batch_size=100):\n",
        "    \"\"\"\n",
        "    Check accuracy of the model on the provided data.\n",
        "\n",
        "    Inputs:\n",
        "    - model: Image classifier\n",
        "    - X: Array of data, of shape (N, d_1, ..., d_k)\n",
        "    - y: Array of labels, of shape (N,)\n",
        "    - num_samples: If not None, subsample the data and only test the model\n",
        "      on num_samples datapoints.\n",
        "    - batch_size: Split X and y into batches of this size to avoid using\n",
        "      too much memory.\n",
        "\n",
        "    Returns:\n",
        "    - acc: Scalar giving the fraction of instances that were correctly\n",
        "      classified by the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Subsample the data\n",
        "    N = X.shape[0]\n",
        "    if num_samples is not None and N > num_samples:\n",
        "        mask = np.random.choice(N, num_samples)\n",
        "        N = num_samples\n",
        "        X = X[mask]\n",
        "        y = y[mask]\n",
        "\n",
        "    # Compute predictions in batches\n",
        "    num_batches = N // batch_size\n",
        "    if N % batch_size != 0:\n",
        "        num_batches += 1\n",
        "    y_pred = []\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        scores = model.forwards_backwards(X[start:end])\n",
        "        y_pred.append(np.argmax(scores, axis=1))\n",
        "    y_pred = np.hstack(y_pred)\n",
        "    acc = np.mean(y_pred == y)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def SGD(W,dW, learning_rate=1e-3):\n",
        "    \"\"\" Apply a gradient descent step on weight W \n",
        "    Inputs:\n",
        "        W : Weight matrix\n",
        "        dW : gradient of weight, same shape as W\n",
        "        learning_rate : Learning rate. Defaults to 1e-3.\n",
        "    Returns:\n",
        "        new_W: Updated weight matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Apply a gradient descent step on weight W using the gradient dW and the specified learning rate.\n",
        "    new_W = W - learning_rate * dW\n",
        "\n",
        "    return new_W\n",
        "\n",
        "def trainNetwork(model, data, **kwargs):\n",
        "    \"\"\"\n",
        "     Required arguments:\n",
        "    - model: Image classifier\n",
        "    - data: A dictionary of training and validation data containing:\n",
        "      'X_train': Array, shape (N_train, d_1, ..., d_k) of training images\n",
        "      'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images\n",
        "      'y_train': Array, shape (N_train,) of labels for training images\n",
        "      'y_val': Array, shape (N_val,) of labels for validation images\n",
        "\n",
        "    Optional arguments:\n",
        "    - learning_rate: A scalar for initial learning rate.\n",
        "    - lr_decay: A scalar for learning rate decay; after each epoch the\n",
        "      learning rate is multiplied by this value.\n",
        "    - batch_size: Size of minibatches used to compute loss and gradient\n",
        "      during training.\n",
        "    - num_epochs: The number of epochs to run for during training.\n",
        "    - print_every: Integer; training losses will be printed every\n",
        "      print_every iterations.\n",
        "    - verbose: Boolean; if set to false then no output will be printed\n",
        "      during training.\n",
        "    - num_train_samples: Number of training samples used to check training\n",
        "      accuracy; default is 1000; set to None to use entire training set.\n",
        "    - num_val_samples: Number of validation samples to use to check val\n",
        "      accuracy; default is None, which uses the entire validation set.\n",
        "    - optimizer: Choice of using either 'SGD' or 'SGD_Momentum' for updating weights; default is SGD.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    learning_rate =  kwargs.pop('learning_rate', 1e-3)\n",
        "    lr_decay = kwargs.pop('lr_decay', 1.0)\n",
        "    batch_size = kwargs.pop('batch_size', 100)\n",
        "    num_epochs = kwargs.pop('num_epochs', 10)\n",
        "    num_train_samples = kwargs.pop('num_train_samples', 1000)\n",
        "    num_val_samples = kwargs.pop('num_val_samples', None)\n",
        "    print_every = kwargs.pop('print_every', 10)   \n",
        "    verbose = kwargs.pop('verbose', True)\n",
        "    optimizer = kwargs.pop('optimizer', 'SGD')\n",
        "    \n",
        "    epoch = 0\n",
        "    best_val_acc = 0\n",
        "    best_params = {}\n",
        "    loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    \n",
        "    \n",
        "    num_train = data['X_train'].shape[0]\n",
        "    iterations_per_epoch = max(num_train // batch_size, 1)\n",
        "    num_iterations = num_epochs * iterations_per_epoch\n",
        "    \n",
        "    #Initialize velocity dictionary if optimizer is SGD_Momentum\n",
        "    if optimizer == 'SGD_Momentum':\n",
        "      velocity_dict = {p:np.zeros(w.shape) for p,w in model.params.items()}\n",
        "      \n",
        "    for t in range(num_iterations):\n",
        "        # Make a minibatch of training data\n",
        "        batch_mask = np.random.choice(num_train, batch_size)\n",
        "        X_batch = data['X_train'][batch_mask]\n",
        "        y_batch = data['y_train'][batch_mask]\n",
        "        # Compute loss and gradient\n",
        "        loss, grads = model.forwards_backwards(X_batch, y_batch)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        if optimizer == 'SGD':\n",
        "          for p, w in model.params.items():\n",
        "              model.params[p] = SGD(w,grads[p], learning_rate=learning_rate)\n",
        "\n",
        "        elif optimizer == 'SGD_Momentum':\n",
        "          for p, w in model.params.items():\n",
        "              model.params[p], velocity_dict[p] = SGD_Momentum(w, grads[p], velocity_dict[p], beta=0.5, learning_rate=learning_rate)\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "        # Print training loss\n",
        "        if verbose and t % print_every == 0:\n",
        "            print('(Iteration %d / %d) loss: %f' % (\n",
        "                   t + 1, num_iterations, loss_history[-1]))\n",
        "         \n",
        "        # At the end of every epoch, increment the epoch counter and decay\n",
        "        # the learning rate.\n",
        "        epoch_end = (t + 1) % iterations_per_epoch == 0\n",
        "        if epoch_end:\n",
        "            epoch += 1\n",
        "            learning_rate *= lr_decay\n",
        "        \n",
        "        # Check train and val accuracy on the first iteration, the last\n",
        "        # iteration, and at the end of each epoch.\n",
        "        first_it = (t == 0)\n",
        "        last_it = (t == num_iterations - 1)\n",
        "        if first_it or last_it or epoch_end:\n",
        "            train_acc = testNetwork(model, data['X_train'], data['y_train'],\n",
        "                num_samples= num_train_samples)\n",
        "            val_acc = testNetwork(model, data['X_val'], data['y_val'],\n",
        "                num_samples=num_val_samples)\n",
        "            train_acc_history.append(train_acc)\n",
        "            val_acc_history.append(val_acc)\n",
        "\n",
        "            if verbose:\n",
        "                print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
        "                       epoch, num_epochs, train_acc, val_acc))\n",
        "\n",
        "            # Keep track of the best model\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_params = {}\n",
        "                for k, v in model.params.items():\n",
        "                    best_params[k] = v.copy()\n",
        "        \n",
        "    model.params = best_params\n",
        "        \n",
        "    return model, train_acc_history, val_acc_history\n",
        "        \n",
        "\n",
        "# load data\n",
        "data = load_cifar10() \n",
        "train_data = { k: data[k] for k in ['X_train', 'y_train', \n",
        "                                    'X_val', 'y_val']}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# initialize model\n",
        "model_SGD = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
        "\n",
        "#######################################################################\n",
        "# TODO: Set up model hyperparameters for SGD                          #\n",
        "#######################################################################\n",
        "# set the hyperparameter\n",
        "learning_rate_SGD = 0.004\n",
        "lr_decay_SGD = 1.0\n",
        "batch_size_SGD = 100\n",
        "# start training using SGD\n",
        "model_SGD, train_acc_history_SGD, val_acc_history_SGD = trainNetwork(\n",
        "    model_SGD, train_data, \n",
        "    learning_rate = learning_rate_SGD,\n",
        "    lr_decay=lr_decay_SGD, \n",
        "    batch_size=batch_size_SGD,\n",
        "    num_epochs=10, \n",
        "    print_every=1000, optimizer = 'SGD')\n",
        "#######################################################################\n",
        "#                         END OF YOUR CODE                            #\n",
        "#######################################################################\n",
        "\n",
        "print(\"~~~~~~~~~~ %s seconds ~~~~~~~~~~\" % (time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2ilTVXIw_7q"
      },
      "source": [
        "# 4.2(d) Training with SGD_Momentum\n",
        "\n",
        "The model above was trained using SGD. Now implement the SGD with momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54jGVPZOXtV6",
        "outputId": "dffb1f94-560c-4f3e-cc8c-91908191f0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 4000) loss: 2.293499\n",
            "(Epoch 0 / 10) train acc: 0.103000; val_acc: 0.103400\n",
            "(Epoch 1 / 10) train acc: 0.380000; val_acc: 0.349000\n",
            "(Epoch 2 / 10) train acc: 0.413000; val_acc: 0.393500\n",
            "(Iteration 1001 / 4000) loss: 1.563956\n",
            "(Epoch 3 / 10) train acc: 0.437000; val_acc: 0.423300\n",
            "(Epoch 4 / 10) train acc: 0.471000; val_acc: 0.435200\n",
            "(Epoch 5 / 10) train acc: 0.470000; val_acc: 0.448700\n",
            "(Iteration 2001 / 4000) loss: 1.501333\n",
            "(Epoch 6 / 10) train acc: 0.513000; val_acc: 0.463900\n",
            "(Epoch 7 / 10) train acc: 0.512000; val_acc: 0.470000\n",
            "(Iteration 3001 / 4000) loss: 1.392300\n",
            "(Epoch 8 / 10) train acc: 0.511000; val_acc: 0.482100\n",
            "(Epoch 9 / 10) train acc: 0.549000; val_acc: 0.485800\n",
            "(Epoch 10 / 10) train acc: 0.536000; val_acc: 0.490200\n",
            "~~~~~~~~~~ 231.69178414344788 seconds ~~~~~~~~~~\n"
          ]
        }
      ],
      "source": [
        "def SGD_Momentum(W, dW, velocity, beta=0.5, learning_rate=1e-3):\n",
        "    \"\"\" Apply a gradient descent with momentum update on weight W\n",
        "    Inputs:\n",
        "        W : Weight matrix\n",
        "        dW : gradient of weight, same shape as W\n",
        "        velocity : velocity matrix, same shape as W\n",
        "        beta : scalar value in range [0,1] weighting the velocity matrix. Setting it to 0 should make SGD_Momentum same as SGD. \n",
        "               Defaults to 0.5.\n",
        "        learning_rate : Learning rate. Defaults to 1e-3.\n",
        "    Returns:\n",
        "        new_W: Updated weight matrix\n",
        "        new_velocity: Updated velocity matrix\n",
        "    \"\"\"\n",
        "    #######################################################################\n",
        "    # TODO: Apply a gradient descent step on weight W using the gradient dW and the specified learning rate.\n",
        "    # 1. Calculate the new velocity by using the velocity of last iteration (input velocity) and gradient\n",
        "    # 2. Update the weights using the new_velocity\n",
        "    #######################################################################\n",
        "    beta = 0.5\n",
        "    new_velocity = beta * velocity - learning_rate * dW\n",
        "    new_W = W + new_velocity\n",
        "    #######################################################################\n",
        "    #                         END OF YOUR CODE                            #\n",
        "    #######################################################################\n",
        "    return new_W, new_velocity\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# initialize model\n",
        "model_SGD_Momentum = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
        "\n",
        "# start training \n",
        "#Using SGD_Momentum as optimizer for trainning for training\n",
        "model_SGD_Momentum, train_acc_history_SGD_Momentum, val_acc_history_SGD_Momentum = trainNetwork(\n",
        "    model_SGD_Momentum, train_data, \n",
        "    learning_rate = learning_rate_SGD,\n",
        "    lr_decay=lr_decay_SGD, \n",
        "    batch_size=batch_size_SGD,\n",
        "    num_epochs=10, \n",
        "    print_every=1000, optimizer = 'SGD_Momentum')\n",
        "print(\"~~~~~~~~~~ %s seconds ~~~~~~~~~~\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcovGmpXvXXa"
      },
      "source": [
        "# 4.2(e) Report Accuracy\n",
        "\n",
        "Run the given code and report the accuracy of model_SGD and model_SGD_Momentum on test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FwCq8pBhu6dz",
        "outputId": "437cd353-8aaa-48c7-abc7-f12e5fff2843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy of model_SGD: 0.4611\n",
            "Test accuracy of model_SGD_Momentum: 0.4919\n"
          ]
        }
      ],
      "source": [
        "# report test accuracy\n",
        "acc = testNetwork(model_SGD, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of model_SGD: {}\".format(acc))\n",
        "# report test accuracy\n",
        "acc = testNetwork(model_SGD_Momentum, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of model_SGD_Momentum: {}\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTrmbULS7i2N"
      },
      "source": [
        "# 4.2(f) Plot\n",
        "\n",
        "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot, using SGD and SGD_Momentum as optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPjtnbya9S7g",
        "outputId": "c4a308ee-247c-4322-d2cf-568b73c27e31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7f7d807e6c18>"
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#######################################################################\n",
        "# Your Code here\n",
        "#######################################################################\n",
        "plt.plot(np.arange(1, len(train_acc_history_SGD) + 1), train_acc_history_SGD, 'o-')\n",
        "\n",
        "plt.xlabel('Epoch Index')\n",
        "\n",
        "plt.ylabel('Accuracy of SGD History')\n",
        "\n",
        "plt.plot(np.arange(1, len(val_acc_history_SGD) + 1), val_acc_history_SGD, 'o-')\n",
        "\n",
        "plt.plot(np.arange(1, len(train_acc_history_SGD_Momentum) + 1), train_acc_history_SGD_Momentum, 'o-')\n",
        "\n",
        "plt.plot(np.arange(1, len(val_acc_history_SGD_Momentum) + 1), val_acc_history_SGD_Momentum, 'o-')\n",
        "\n",
        "plt.legend(['Train without momentum', 'Val without momentum', 'Train with momentum', 'Val with momentum'])\n",
        "#######################################################################\n",
        "#                         END OF YOUR CODE                            #\n",
        "#######################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report your obervation here:"
      ],
      "metadata": {
        "id": "GVcoULZa5seR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxOkNE5IE76I"
      },
      "source": [
        "# 4.2(g) Adding L2 regularization (EECS 504 Only)\n",
        "\n",
        "Add L2 regularization to the softmax classifier in 4.2(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2(h) Training with L2 regularization (EECS 504 Only)\n",
        "\n",
        "Train the model again using L2 regularization, using SGD"
      ],
      "metadata": {
        "id": "e3VuqVbKh6VB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQoj9kabUBy8",
        "outputId": "b6454f81-ec4a-4f08-9630-7d5208f6affd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 4000) loss: 2.308364\n",
            "(Epoch 0 / 10) train acc: 0.090000; val_acc: 0.088400\n",
            "(Epoch 1 / 10) train acc: 0.328000; val_acc: 0.310400\n",
            "(Epoch 2 / 10) train acc: 0.354000; val_acc: 0.354600\n",
            "(Iteration 1001 / 4000) loss: 1.880790\n",
            "(Epoch 3 / 10) train acc: 0.414000; val_acc: 0.376500\n",
            "(Epoch 4 / 10) train acc: 0.397000; val_acc: 0.392000\n",
            "(Epoch 5 / 10) train acc: 0.402000; val_acc: 0.408700\n",
            "(Iteration 2001 / 4000) loss: 1.561081\n",
            "(Epoch 6 / 10) train acc: 0.441000; val_acc: 0.421100\n",
            "(Epoch 7 / 10) train acc: 0.457000; val_acc: 0.431200\n",
            "(Iteration 3001 / 4000) loss: 1.571822\n",
            "(Epoch 8 / 10) train acc: 0.473000; val_acc: 0.437900\n",
            "(Epoch 9 / 10) train acc: 0.458000; val_acc: 0.445200\n",
            "(Epoch 10 / 10) train acc: 0.499000; val_acc: 0.452200\n",
            "~~~~~~~~~~ 270.0305423736572 seconds ~~~~~~~~~~\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# initialize model (remember to set the l2 regularization weight > 0)\n",
        "model_SGD_L2 = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2, reg=0.01)\n",
        "\n",
        "# start training using SGD. The training hyperparameter you choose should be same to the 4.2(c)\n",
        "model_SGD_L2, train_acc_history_SGD_L2, val_acc_history_SGD_L2 = trainNetwork(\n",
        "    model_SGD_L2, train_data, \n",
        "    learning_rate = learning_rate_SGD,\n",
        "    lr_decay=lr_decay_SGD, \n",
        "    batch_size=batch_size_SGD,\n",
        "    num_epochs=10, \n",
        "    print_every=1000, optimizer = 'SGD')\n",
        "\n",
        "print(\"~~~~~~~~~~ %s seconds ~~~~~~~~~~\" % (time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5yYAg3mWFX5",
        "outputId": "6ed75fe5-104a-4a83-86e6-6d1cff32ff42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy of model_SGD_L2: 0.4622\n"
          ]
        }
      ],
      "source": [
        "# report test accuracy\n",
        "acc = testNetwork(model_SGD_L2, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of model_SGD_L2: {}\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2(i) Plot\n",
        "\n",
        "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot for model with and without L2 regularization, using SGD as optimizer. "
      ],
      "metadata": {
        "id": "9AuWH2_Aj2Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# TODO: Your Code here\n",
        "#######################################################################\n",
        "plt.plot(np.arange(1, len(train_acc_history_SGD) + 1), train_acc_history_SGD, 'o-')\n",
        "\n",
        "plt.xlabel('Epoch Index')\n",
        "\n",
        "plt.ylabel('Accuracy of SGD History')\n",
        "\n",
        "plt.plot(np.arange(1, len(val_acc_history_SGD) + 1), val_acc_history_SGD, 'o-')\n",
        "\n",
        "plt.plot(np.arange(1, len(train_acc_history_SGD_L2) + 1), train_acc_history_SGD_L2, 'o-')\n",
        "\n",
        "plt.plot(np.arange(1, len(val_acc_history_SGD_L2) + 1), val_acc_history_SGD_L2, 'o-')\n",
        "\n",
        "plt.legend(['Train without L2 Reg', 'Val without L2 Reg', 'Train with L2 Reg', 'Val with L2 Reg'])\n",
        "#######################################################################\n",
        "#                         END OF YOUR CODE                            #\n",
        "#######################################################################"
      ],
      "metadata": {
        "id": "eG7H8nXCgudY",
        "outputId": "888df1db-39c1-4ae0-a848-e10453f00c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7f7d89aa86d8>"
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2(j) Tune your own model\n",
        "\n",
        "Feel free to tune any hyperparameters and choose any optimizer as you want -- just train the best model you can!"
      ],
      "metadata": {
        "id": "MbrfhTzdlyRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# TODO: Train your own model                                          #\n",
        "#######################################################################\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# initialize model (set reg=0.0 for EECS 442 students)\n",
        "your_model = SoftmaxClassifier(hidden_dim = 300, weight_scale=0.01,  reg= 0.01)\n",
        "\n",
        "# train your moodel\n",
        "your_model, train_acc_history_your_model, val_acc_history_your_model = trainNetwork(\n",
        "    your_model, train_data, \n",
        "    learning_rate = 0.004,\n",
        "    lr_decay=  1.0,\n",
        "    batch_size=  100,\n",
        "    num_epochs= 20,\n",
        "    print_every=1000, optimizer = 'SGD_Momentum')\n",
        "\n",
        "print(\"~~~~~~~~~~ %s seconds ~~~~~~~~~~\" % (time.time() - start_time))\n",
        "\n",
        "#######################################################################\n",
        "#                         END OF YOUR CODE                            #\n",
        "#######################################################################"
      ],
      "metadata": {
        "id": "SrjE2jyKmY-9",
        "outputId": "03439739-e872-460b-f388-ec8fc7950c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 8000) loss: 2.306176\n",
            "(Epoch 0 / 20) train acc: 0.097000; val_acc: 0.114300\n",
            "(Epoch 1 / 20) train acc: 0.375000; val_acc: 0.352400\n",
            "(Epoch 2 / 20) train acc: 0.386000; val_acc: 0.392700\n",
            "(Iteration 1001 / 8000) loss: 1.710751\n",
            "(Epoch 3 / 20) train acc: 0.462000; val_acc: 0.421400\n",
            "(Epoch 4 / 20) train acc: 0.443000; val_acc: 0.435600\n",
            "(Epoch 5 / 20) train acc: 0.495000; val_acc: 0.451700\n",
            "(Iteration 2001 / 8000) loss: 1.528847\n",
            "(Epoch 6 / 20) train acc: 0.499000; val_acc: 0.454000\n",
            "(Epoch 7 / 20) train acc: 0.491000; val_acc: 0.466000\n",
            "(Iteration 3001 / 8000) loss: 1.474396\n",
            "(Epoch 8 / 20) train acc: 0.511000; val_acc: 0.474200\n",
            "(Epoch 9 / 20) train acc: 0.534000; val_acc: 0.486100\n",
            "(Epoch 10 / 20) train acc: 0.545000; val_acc: 0.493500\n",
            "(Iteration 4001 / 8000) loss: 1.285978\n",
            "(Epoch 11 / 20) train acc: 0.556000; val_acc: 0.492800\n",
            "(Epoch 12 / 20) train acc: 0.576000; val_acc: 0.502400\n",
            "(Iteration 5001 / 8000) loss: 1.312741\n",
            "(Epoch 13 / 20) train acc: 0.567000; val_acc: 0.502900\n",
            "(Epoch 14 / 20) train acc: 0.586000; val_acc: 0.507700\n",
            "(Epoch 15 / 20) train acc: 0.592000; val_acc: 0.507700\n",
            "(Iteration 6001 / 8000) loss: 1.296600\n",
            "(Epoch 16 / 20) train acc: 0.615000; val_acc: 0.510500\n",
            "(Epoch 17 / 20) train acc: 0.618000; val_acc: 0.513700\n",
            "(Iteration 7001 / 8000) loss: 1.360167\n",
            "(Epoch 18 / 20) train acc: 0.610000; val_acc: 0.518200\n",
            "(Epoch 19 / 20) train acc: 0.654000; val_acc: 0.515400\n",
            "(Epoch 20 / 20) train acc: 0.637000; val_acc: 0.519500\n",
            "~~~~~~~~~~ 584.0886147022247 seconds ~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# report test accuracy \n",
        "# (Run this code only once when you obtain the highest model in validation set!)\n",
        "acc = testNetwork(your_model, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of your model: {}\".format(acc))"
      ],
      "metadata": {
        "id": "vI4SK0PPmbrE",
        "outputId": "008947d3-452a-4cf5-ffc1-0cebaac0560a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy of your model: 0.5121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7MoINIIhYf7"
      },
      "source": [
        "# Convert Notebook to PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z5w3nymDr3_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f94a063-1973-44ce-fcc8-65207848337c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,324 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,424 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,546 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,992 kB]\n",
            "Fetched 11.5 MB in 3s (3,801 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto apache2 | lighttpd | httpd poppler-utils ghostscript\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf-reader\n",
            "  | pdf-viewer texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-generic-recommended\n",
            "  texlive-latex-base texlive-latex-extra texlive-latex-recommended\n",
            "  texlive-pictures texlive-plain-generic texlive-xetex tipa\n",
            "0 upgraded, 47 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 146 MB of archives.\n",
            "After this operation, 460 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.9 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.17 [5,092 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.17 [2,267 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.12 [48.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.12 [3,073 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-generic-recommended all 2017.20180305-1 [15.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-xetex all 2017.20180305-1 [10.7 MB]\n",
            "Fetched 146 MB in 2s (67.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../06-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../07-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../08-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../09-libcupsimage2_2.2.7-1ubuntu2.9_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../10-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../11-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../12-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.17_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.26~dfsg+0-0ubuntu0.18.04.17_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../14-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../15-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../16-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../17-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../18-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../19-ruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../20-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../21-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../22-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../23-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../24-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../25-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../26-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../27-libruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../28-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../29-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../30-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../31-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../32-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../33-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../34-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../35-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../36-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../37-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../38-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../39-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-generic-recommended.\n",
            "Preparing to unpack .../40-texlive-generic-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-generic-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../41-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../42-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../43-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../44-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../45-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../46-texlive-xetex_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-xetex (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-generic-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up texlive-xetex (2017.20180305-1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/ruiche_87169154_ps4.ipynb to PDF\n",
            "[NbConvertApp] Support files will be in ruiche_87169154_ps4_files/\n",
            "[NbConvertApp] Making directory ./ruiche_87169154_ps4_files\n",
            "[NbConvertApp] Making directory ./ruiche_87169154_ps4_files\n",
            "[NbConvertApp] Writing 156431 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 153929 bytes to /content/drive/My Drive/Colab Notebooks/ruiche_87169154_ps4.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af4c3d0d-90d9-4422-8cd5-c4546ac4c313\", \"ruiche_87169154_ps4.pdf\", 153929)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive_mount_point = '/content/drive/'\n",
        "drive.mount(drive_mount_point)\n",
        "notebookpath = '/content/drive/My Drive/Colab Notebooks/ruiche_87169154_ps4.ipynb' \n",
        "file_name = notebookpath.split('/')[-1]\n",
        "get_ipython().system(\"apt update && apt install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\")\n",
        "get_ipython().system(\"jupyter nbconvert --to PDF {}\".format(notebookpath.replace(' ', '\\\\ ')))\n",
        "files.download(notebookpath.split('.')[0]+'.pdf')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}